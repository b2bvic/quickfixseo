#!/usr/bin/env python3
"""
Advanced SEO Audit System - Enterprise Edition
Features:
- AI-powered content quality analysis
- Mobile-first indexing optimization
- Competitive positioning analysis
- Advanced schema markup detection
- Page experience signals monitoring
- Core Web Vitals tracking
"""

import sys
import os
from obsidian_seo_crawler import ComprehensiveSEOCrawler

def main():
    print("ğŸš€ Advanced SEO Audit System - Enterprise Edition")
    print("=" * 60)
    print("ğŸ§  AI-Powered Content Analysis")
    print("ğŸ“± Mobile-First Indexing Optimization")
    print("ğŸ† Competitive Positioning Analysis")
    print("ğŸ” Advanced Schema Markup Detection")
    print("âš¡ Page Experience Signals Monitoring")
    print("ğŸ“Š Core Web Vitals Tracking")
    print("=" * 60)
    
    if len(sys.argv) != 2:
        print("\nUsage: python3 advanced_seo_audit.py <website_url>")
        print("\nExamples:")
        print("  python3 advanced_seo_audit.py https://example.com")
        print("  python3 advanced_seo_audit.py example.com")
        print("\nFeatures:")
        print("â€¢ ğŸ§  Content quality scoring with readability analysis")
        print("â€¢ ğŸ“± Mobile-first indexing compliance checks")
        print("â€¢ ğŸ† Competitive benchmarking and positioning")
        print("â€¢ ğŸ” Intelligent schema markup recommendations")
        print("â€¢ âš¡ Page experience signals analysis")
        print("â€¢ ğŸ“Š Advanced performance metrics")
        print("â€¢ ğŸ¯ AI-powered optimization recommendations")
        sys.exit(1)
    
    url = sys.argv[1]
    
    # Add https:// if not present
    if not url.startswith(('http://', 'https://')):
        url = 'https://' + url
    
    print(f"\nğŸ¯ Target Website: {url}")
    print(f"ğŸ” Analysis Mode: Enterprise-Level Comprehensive Audit")
    
    # Initialize the advanced crawler
    try:
        crawler = ComprehensiveSEOCrawler()
        print(f"ğŸ“ Reports will be saved to: {crawler.seo_audits_folder}")
        
        # Run comprehensive analysis with all advanced features
        print(f"\nğŸš€ Starting advanced SEO analysis...")
        print("   This includes:")
        print("   â€¢ Technical infrastructure analysis")
        print("   â€¢ Content quality assessment with AI scoring")
        print("   â€¢ Mobile-first indexing compliance")
        print("   â€¢ Schema markup intelligence")
        print("   â€¢ Competitive positioning analysis")
        print("   â€¢ Page experience signals monitoring")
        
        analysis = crawler.comprehensive_analysis(url)
        
        # Generate the enhanced report
        print(f"\nğŸ“Š Generating enterprise-level audit report...")
        crawler.generate_comprehensive_markdown(analysis)
        
        print(f"\nâœ… Advanced SEO audit completed successfully!")
        print(f"ğŸ“„ Report saved to: {crawler.seo_audits_folder}")
        
        # Display key insights
        print(f"\nğŸ” Key Insights:")
        print(f"   â€¢ Pages analyzed: {analysis.get('total_pages', 'N/A')}")
        if 'seo_issues' in analysis:
            print(f"   â€¢ SEO issues found: {len(analysis['seo_issues'])}")
        else:
            print(f"   â€¢ SEO issues found: Analysis in progress")
        
        if 'competitive_analysis' in analysis:
            comp_score = analysis['competitive_analysis']['competitive_score']
            print(f"   â€¢ Competitive score: {comp_score:.1f}/100")
            
            if comp_score >= 80:
                print(f"   â€¢ ğŸ† Excellent competitive positioning")
            elif comp_score >= 60:
                print(f"   â€¢ ğŸ“Š Good foundation with improvement opportunities")
            else:
                print(f"   â€¢ ğŸš€ High potential for ranking improvements")
        
        # Advanced recommendations
        if analysis.get('recommendations'):
            print(f"\nğŸ¯ Top Recommendations:")
            for i, rec in enumerate(analysis['recommendations'][:3], 1):
                print(f"   {i}. {rec}")
        
        print(f"\nğŸ“ˆ Next Steps:")
        print(f"   1. Review the detailed audit report in your Obsidian vault")
        print(f"   2. Prioritize critical issues for immediate attention")
        print(f"   3. Implement mobile-first optimizations")
        print(f"   4. Enhance content quality based on AI analysis")
        print(f"   5. Monitor competitive positioning improvements")
        
    except Exception as e:
        print(f"\nâŒ Error during advanced analysis: {str(e)}")
        print(f"ğŸ’¡ Troubleshooting tips:")
        print(f"   â€¢ Ensure the website is accessible")
        print(f"   â€¢ Check your internet connection")
        print(f"   â€¢ Verify the URL is correct")
        print(f"   â€¢ Install required dependencies: pip install -r requirements.txt")
        sys.exit(1)

if __name__ == "__main__":
    main() 